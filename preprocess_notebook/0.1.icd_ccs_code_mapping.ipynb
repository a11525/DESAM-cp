{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP ICD-9-CM to CCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_path = '/ssd2/sanghoon/data/EHR/mimic3/mimic3' #your mimic3 folder\n",
    "save_path = '../data'\n",
    "patitentTM_preprocessing_path='/home/sanghoon/drug/project/EHR/PatientTM/data/extended/preprocessing'# your patientIM prerpocessing folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using code : []\n",
    "def featureToIdx(features):\n",
    "    feature2idx = {}\n",
    "    feature2idx[\"0\"] = 0 #will be used to mask padding \"codes\" in the model\n",
    "    idx=1\n",
    "    for entry in features:\n",
    "        if entry in feature2idx.keys():\n",
    "            pass\n",
    "        else:# print(idx, entry)\n",
    "            feature2idx[entry] = idx\n",
    "            idx+=1\n",
    "    return feature2idx\n",
    "\n",
    "\n",
    "def getICDlevel1(icd9_code):\n",
    "    \"\"\"\n",
    "    This method extracts the first level of hierarchy of an ICD code:\n",
    "        - Procedure codes start with P_xxxx and only have 2 digits in the first level so we extract P_xx\n",
    "        - Diagnoses codes start with D_ and can have the following formats (1) Exxx (2) Vxx (3) xxx \n",
    "    \"\"\"\n",
    "    if icd9_code.startswith(\"P\"):\n",
    "        return icd9_code[:4]\n",
    "    elif icd9_code.startswith(\"D\"):\n",
    "        if icd9_code.startswith(\"D_E\"):\n",
    "            return icd9_code[:6]\n",
    "        else:\n",
    "            return icd9_code[:5]\n",
    "\n",
    "        \n",
    "def map_ICD9_to_CCS(patiemtTM_proprocess_path,pandasDataFrame):\n",
    "    # icd_cds_path : PatientTM's merged_icdccs_codes.json file path\n",
    "    with open(patiemtTM_proprocess_path+'/ICDandCCSmappings/merged_icdccs_codes.json','r') as file:\n",
    "        icd9TOCCS_Map = json.load(file)\n",
    "    #mappedSmallICDList = []\n",
    "    mappedCCSList = []\n",
    "    unmapped=0\n",
    "    mapped=0\n",
    "    for row in pandasDataFrame.itertuples():\n",
    "        #tempSmallICDCodeList = []\n",
    "        tempCCSCodeList = []\n",
    "        for ICD9 in row.ICD9_CODE:\n",
    "            #smallICD = getICDlevel1(ICD9)\n",
    "            #if smallICD not in tempSmallICDCodeList: tempSmallICDCodeList.append(smallICD)\n",
    "            try:\n",
    "                CCS_code = icd9TOCCS_Map[ICD9]\n",
    "                tempCCSCodeList.append(CCS_code)\n",
    "                mapped+=1\n",
    "            except KeyError:\n",
    "    ## This was previously added but we decided to simply not introduce more noise if the map is unsuccessful\n",
    "                # tempCCSCodeList.append(\"0\") #Used for NaN entries\n",
    "                unmapped+=1\n",
    "        #mappedSmallICDList.append(tempSmallICDCodeList)\n",
    "        mappedCCSList.append(tempCCSCodeList)\n",
    "    print(\"-Total of mapped/unmapped entries {}/{}\".format(mapped,unmapped))\n",
    "    return mappedCCSList #, mappedSmallICDList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx_fold=patitentTM_preprocessing_path+'/idxFiles/'\n",
    "emb_fold=patitentTM_preprocessing_path+'/embeddings/'\n",
    "\n",
    "\n",
    "using_feature = ['DIAGNOSES_ICD', 'ADMISSIONS']\n",
    "data_dict ={}\n",
    "\n",
    "for file in using_feature:\n",
    "    temp_name = file +'.csv'\n",
    "    \n",
    "    data_dict[file.lower()] = pd.read_csv(mimic_path+'/'+temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y =data_dict['admissions'][['HADM_ID','HOSPITAL_EXPIRE_FLAG']].set_index('HADM_ID')\n",
    "diagnosis = pd.DataFrame(data_dict['diagnoses_icd'].groupby('HADM_ID')['ICD9_CODE'].apply(list))\n",
    "\n",
    "\n",
    "diagnosis =diagnosis.rename(columns={'ICD9_CODE': 'diagnosis_icd9'}).reset_index()\n",
    "\n",
    "\n",
    "merge_pd = pd.merge(data_dict['admissions'],diagnosis,how='left', on='HADM_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Total of mapped/unmapped entries 651000/0\n"
     ]
    }
   ],
   "source": [
    "df_diagnoses = data_dict['diagnoses_icd'][data_dict['diagnoses_icd'].ICD9_CODE.notna()]\n",
    "df_diagnoses = df_diagnoses.sort_values(['HADM_ID','SEQ_NUM'], ascending=True)\n",
    "df_diagnoses = df_diagnoses.reset_index(drop = True)\n",
    "df_diagnoses.ICD9_CODE = \"D_\" + df_diagnoses.ICD9_CODE.astype(str)\n",
    "df_diag_listing = df_diagnoses.groupby('HADM_ID')['ICD9_CODE'].apply(list)\n",
    "df_diag_listing = df_diag_listing.reset_index()\n",
    "diagnosesCCS = map_ICD9_to_CCS(patitentTM_preprocessing_path,df_diag_listing)\n",
    "#df_diag_listing['SMALL_DIAG_ICD9'] = smallICDs\n",
    "df_diag_listing['DIAG_CCS'] = diagnosesCCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D_25013',\n",
       " 'D_3371',\n",
       " 'D_5849',\n",
       " 'D_5780',\n",
       " 'D_V5867',\n",
       " 'D_25063',\n",
       " 'D_5363',\n",
       " 'D_4580',\n",
       " 'D_25043',\n",
       " 'D_40390',\n",
       " 'D_5853',\n",
       " 'D_25053',\n",
       " 'D_36201',\n",
       " 'D_25083',\n",
       " 'D_7078',\n",
       " 'D_V1351']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diag_listing['ICD9_CODE'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm = pd.merge(merge_pd,\n",
    "                  df_diag_listing[['HADM_ID','ICD9_CODE','DIAG_CCS']],\n",
    "                  on = ['HADM_ID'],\n",
    "                  how = 'left')\n",
    "df_adm = df_adm.rename(columns={'ICD9_CODE': 'DIAG_ICD9'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm.to_csv(save_path+'/preprocessed.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCS code indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx_fold=patitentTM_preprocessing_path+'/idxFiles/'\n",
    "emb_fold=patitentTM_preprocessing_path+'/embeddings/'\n",
    "\n",
    "with open(idx_fold+'CCSToIdx.json',\"r\") as file:\n",
    "    ccs2idx = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def convert2idx(df_row, idx_dict, col_name):\n",
    "    \n",
    "    if pd.isnull(df_row[col_name]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        key_list = ast.literal_eval(df_row[col_name])\n",
    "        idx_list=[]\n",
    "        for key in key_list:\n",
    "            \n",
    "            if key in ['P_3601', 'P_3602','D_71970','P_3605']:\n",
    "                idx_list.append(0)\n",
    "            else:\n",
    "                try:\n",
    "                    idx_list.append(idx_dict[key])\n",
    "                except:\n",
    "                    idx_list.append(idx_dict[key.split('_')[0]+'_0'+ key.split('_')[1]])\n",
    "                    #idx_list.append(idx_dict[convert_dict[key]])\n",
    "            \n",
    "        #idx_list = list(map(lambda x : idx_dict[x], key_list))\n",
    "\n",
    "        return idx_list\n",
    "def check_del_key(df_row, idx_dict, col_name):\n",
    "    if pd.isnull(df_row[col_name]):\n",
    "        return 'nan'\n",
    "    else:\n",
    "        key_list = ast.literal_eval(df_row[col_name])\n",
    "        idx_list=[]\n",
    "        for key in key_list:\n",
    "            try:\n",
    "                idx_dict[key]\n",
    "                return 'nan'\n",
    "            except:\n",
    "                return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(save_path+'/preprocessed.csv')\n",
    "data['DIAG_CCS'] = data.apply(lambda x : convert2idx(x, ccs2idx, 'DIAG_CCS'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(save_path+'/preprocessed_emb_idx.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit",
   "language": "python",
   "name": "rdkit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
