{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_max_len_text(x):\n",
    "    max_len=-1\n",
    "    max_len_text =''\n",
    "    for time_doc in x:\n",
    "        \n",
    "        temp_doc = ' '.join(time_doc)\n",
    "        if len(temp_doc)>max_len:\n",
    "            max_len = len(temp_doc)\n",
    "            max_len_text = temp_doc\n",
    "    \n",
    "    return max_len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_max_len_sentence(x):\n",
    "    max_len=-1\n",
    "    max_len_text =''\n",
    "    for time_doc in x:\n",
    "        \n",
    "        temp_doc = ' '.join(time_doc)\n",
    "        if len(temp_doc)>max_len:\n",
    "            max_len = len(temp_doc)\n",
    "            max_len_text = time_doc\n",
    "    \n",
    "    return max_len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "preprocessed_notes = pd.read_pickle(data_path+'preprocessed_notes.pkl')\n",
    "labels=pd.read_csv(data_path+'label_last_visit.csv')\n",
    "split_path = data_path + 'split_0/'\n",
    "train_subj = pd.read_pickle(split_path+'train_hadm_idx.pkl')\n",
    "dev_subj = pd.read_pickle(split_path+'dev_hadm_idx.pkl')\n",
    "test_subj = pd.read_pickle(split_path+'test_hadm_idx.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22752, 3250, 6502)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_subj), len(dev_subj), len(test_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_notes=preprocessed_notes.sort_values('CHARTTIME')\n",
    "#preprocessed_notes['preprocessed_text']= preprocessed_notes['preprocessed_text'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for bert tokeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text=preprocessed_notes.groupby(['subject_id','hadm_id_y','CHARTTIME']).preprocessed_text.apply(check_max_len_sentence)\n",
    "max_len_text=max_len_text.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10:23 pm chest ( portable ap ) clip # reason : please eval for ptx , chf , effusions , infiltrates',\n",
       " 'medical condition :',\n",
       " '76 year old man with hypotension , vfib arrest , status post rsc line placement .',\n",
       " 'reason for this examination :',\n",
       " 'please eval for ptx , chf , effusions , infiltrates',\n",
       " 'final report',\n",
       " 'indications : hypertension , v-fib rest , s/p right subclavian line placement .',\n",
       " 'portable chest : comparison is made to previous films from four hours prior .',\n",
       " 'findings :',\n",
       " 'there has been placement of a right sided subclavian catheter , with the tip in the proximal svc .',\n",
       " 'additionally , there is a left sided picc line with the tip in the distal svc .',\n",
       " 'there has been interval intubation with endotracheal tube 6.5 cm from the carina .',\n",
       " 'the heart is enlarged , with increased pulmonary vascular markings as well as hilar haziness .',\n",
       " 'additionally , there is bilateral atelectasis and bilateral small effusions .',\n",
       " 'there are no focal opacities or pneumothorax .',\n",
       " 'impression :',\n",
       " '1 .',\n",
       " 'cardiomegaly with unchanged chf .',\n",
       " '2 .',\n",
       " 'intubation with ett at 6.5 cm from the carina .',\n",
       " '3 .',\n",
       " 'interval placement of right subclavian line with the tip in the svc and no pneumothorax .']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_text['preprocessed_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=preprocessed_notes[['hadm_id_y','CHARTTIME','CATEGORY','DESCRIPTION']]\n",
    "tag=tag[tag.duplicated()==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text=max_len_text.merge(tag,'left',on=['hadm_id_y','CHARTTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id           27\n",
       "CHARTTIME            27\n",
       "preprocessed_text    27\n",
       "CATEGORY             27\n",
       "DESCRIPTION          27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_text.groupby('hadm_id_y').count().max() # 27 document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_len_text['count_sentence'] = max_len_text['preprocessed_text'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_max_token(x):\n",
    "    max_len=0\n",
    "    for text in x:\n",
    "        temp_len=len(text.split(' '))\n",
    "        if temp_len > max_len:\n",
    "            max_len=temp_len\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text['max_token'] = max_len_text['preprocessed_text'].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id_y</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>count_sentence</th>\n",
       "      <th>max_token</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case Management</th>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General</th>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nursing</th>\n",
       "      <td>11348</td>\n",
       "      <td>11348</td>\n",
       "      <td>11348</td>\n",
       "      <td>11348</td>\n",
       "      <td>11348</td>\n",
       "      <td>11348</td>\n",
       "      <td>11348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nursing/other</th>\n",
       "      <td>72712</td>\n",
       "      <td>72712</td>\n",
       "      <td>72712</td>\n",
       "      <td>72712</td>\n",
       "      <td>72712</td>\n",
       "      <td>72712</td>\n",
       "      <td>72712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nutrition</th>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pharmacy</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physician</th>\n",
       "      <td>10693</td>\n",
       "      <td>10693</td>\n",
       "      <td>10693</td>\n",
       "      <td>10693</td>\n",
       "      <td>10693</td>\n",
       "      <td>10693</td>\n",
       "      <td>10693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>47231</td>\n",
       "      <td>47231</td>\n",
       "      <td>47231</td>\n",
       "      <td>47231</td>\n",
       "      <td>47231</td>\n",
       "      <td>47231</td>\n",
       "      <td>47231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rehab Services</th>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respiratory</th>\n",
       "      <td>3580</td>\n",
       "      <td>3580</td>\n",
       "      <td>3580</td>\n",
       "      <td>3580</td>\n",
       "      <td>3580</td>\n",
       "      <td>3580</td>\n",
       "      <td>3580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Work</th>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  subject_id  hadm_id_y  CHARTTIME  preprocessed_text  \\\n",
       "CATEGORY                                                                \n",
       "Case Management          111        111        111                111   \n",
       "Consult                   16         16         16                 16   \n",
       "General                 1195       1195       1195               1195   \n",
       "Nursing                11348      11348      11348              11348   \n",
       "Nursing/other          72712      72712      72712              72712   \n",
       "Nutrition                727        727        727                727   \n",
       "Pharmacy                   4          4          4                  4   \n",
       "Physician              10693      10693      10693              10693   \n",
       "Radiology              47231      47231      47231              47231   \n",
       "Rehab Services           266        266        266                266   \n",
       "Respiratory             3580       3580       3580               3580   \n",
       "Social Work              264        264        264                264   \n",
       "\n",
       "                  DESCRIPTION  count_sentence  max_token  \n",
       "CATEGORY                                                  \n",
       "Case Management           111             111        111  \n",
       "Consult                    16              16         16  \n",
       "General                  1195            1195       1195  \n",
       "Nursing                 11348           11348      11348  \n",
       "Nursing/other           72712           72712      72712  \n",
       "Nutrition                 727             727        727  \n",
       "Pharmacy                    4               4          4  \n",
       "Physician               10693           10693      10693  \n",
       "Radiology               47231           47231      47231  \n",
       "Rehab Services            266             266        266  \n",
       "Respiratory              3580            3580       3580  \n",
       "Social Work               264             264        264  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_text.groupby('CATEGORY').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_len_text_r=max_len_text[max_len_text['CATEGORY'].isin(['Social Work', 'Case Management ', 'Rehab Services' , 'Nutrition'])==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text_r= max_len_text_r[max_len_text_r['max_token']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_text_r.groupby('hadm_id_y').count_sentence.sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text_r.to_pickle(data_path+'for_bert_text.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run ../src/make_emb.py to make sentence_to_cbert_cls.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make bert emb shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= pd.read_pickle(data_path+'for_bert_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbert_emb=np.load(data_path+'sentence_to_cbert_cls.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group_st_c = text.groupby('hadm_id_y').count_sentence.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(group_st_c>512).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 146775/146775 [00:09<00:00, 15366.23it/s]\n"
     ]
    }
   ],
   "source": [
    "start=0\n",
    "end=0\n",
    "idx_start=[]\n",
    "for i in tqdm.tqdm(range(len(text))):\n",
    "    temp_c=text.iloc[i]['count_sentence']\n",
    "    idx_start.append(start)\n",
    "    end = start+temp_c\n",
    "    start = end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['idx_start']=idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 30060/30060 [00:51<00:00, 583.22it/s]\n"
     ]
    }
   ],
   "source": [
    "cbert_dict_emb={}\n",
    "hadm_ids=text['hadm_id_y'].unique()\n",
    "for key in tqdm.tqdm(hadm_ids):\n",
    "    temp_notes=text[text['hadm_id_y']==key]\n",
    "    temp_numpy_list=[]\n",
    "    for i in range(len(temp_notes)):\n",
    "        start , c_s =temp_notes.iloc[i][['idx_start','count_sentence']].values\n",
    "        temp_emb=cbert_emb[start:start+c_s]\n",
    "        temp_numpy_list.append(temp_emb)\n",
    "    cbert_dict_emb[key] = np.concatenate(temp_numpy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(cbert_dict_emb,data_path+'cbert_emb_by_hadm.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESAM_py39",
   "language": "python",
   "name": "desam_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
