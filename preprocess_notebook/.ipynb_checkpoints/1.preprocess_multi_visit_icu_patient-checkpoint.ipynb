{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "from multiprocessing import Pool\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is taken from https://github.com/tanlab/ConvolutionMedicalNer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "SECTION_TITLES = re.compile(\n",
    "    r'('\n",
    "    r'ABDOMEN AND PELVIS|CLINICAL HISTORY|CLINICAL INDICATION|COMPARISON|COMPARISON STUDY DATE'\n",
    "    r'|EXAM|EXAMINATION|FINDINGS|HISTORY|IMPRESSION|INDICATION'\n",
    "    r'|MEDICAL CONDITION|PROCEDURE|REASON FOR EXAM|REASON FOR STUDY|REASON FOR THIS EXAMINATION'\n",
    "    r'|TECHNIQUE'\n",
    "    r'):|FINAL REPORT',\n",
    "    re.I | re.M)\n",
    "    \n",
    "    \n",
    "def getSentences(t):\n",
    "    return list(preprocess_mimic(t))\n",
    "    \n",
    "def pattern_repl(matchobj):\n",
    "    \"\"\"\n",
    "    Return a replacement string to be used for match object\n",
    "    \"\"\"\n",
    "    return ' '.rjust(len(matchobj.group(0)))\n",
    "    \n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace [**Patterns**] with spaces.\n",
    "    text = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', pattern_repl, text)\n",
    "    # Replace `_` with spaces.\n",
    "    text = re.sub(r'_', ' ', text)\n",
    "\n",
    "    start = 0\n",
    "    end = find_end(text)\n",
    "    new_text = ''\n",
    "    if start > 0:\n",
    "        new_text += ' ' * start\n",
    "    new_text = text[start:end]\n",
    "\n",
    "    # make sure the new text has the same length of old text.\n",
    "    if len(text) - end > 0:\n",
    "        new_text += ' ' * (len(text) - end)\n",
    "    return new_text\n",
    "\n",
    "def preprocess_mimic(text):\n",
    "    \"\"\"\n",
    "    Preprocess reports in MIMIC-III.\n",
    "    1. remove [**Patterns**] and signature\n",
    "    2. split the report into sections\n",
    "    3. tokenize sentences and words\n",
    "    4. lowercase\n",
    "    \"\"\"\n",
    "    for sec in split_heading(clean_text(text)):\n",
    "        for sent in sent_tokenize(sec):\n",
    "            text = ' '.join(word_tokenize(sent))\n",
    "            yield text.lower()\n",
    "            \n",
    "def split_heading(text):\n",
    "    \"\"\"Split the report into sections\"\"\"\n",
    "    start = 0\n",
    "    for matcher in SECTION_TITLES.finditer(text):\n",
    "        # add last\n",
    "        end = matcher.start()\n",
    "        if end != start:\n",
    "            section = text[start:end].strip()\n",
    "            if section:\n",
    "                yield section\n",
    "\n",
    "        # add title\n",
    "        start = end\n",
    "        end = matcher.end()\n",
    "        if end != start:\n",
    "            section = text[start:end].strip()\n",
    "            if section:\n",
    "                yield section\n",
    "\n",
    "        start = end\n",
    "\n",
    "    # add last piece\n",
    "    end = len(text)\n",
    "    if start < end:\n",
    "        section = text[start:end].strip()\n",
    "        if section:\n",
    "            yield section\n",
    "            \n",
    "def find_end(text):\n",
    "    \"\"\"Find the end of the report.\"\"\"\n",
    "    ends = [len(text)]\n",
    "    patterns = [\n",
    "        re.compile(r'BY ELECTRONICALLY SIGNING THIS REPORT', re.I),\n",
    "        re.compile(r'\\n {3,}DR.', re.I),\n",
    "        re.compile(r'[ ]{1,}RADLINE ', re.I),\n",
    "        re.compile(r'.*electronically signed on', re.I),\n",
    "        re.compile(r'M\\[0KM\\[0KM')\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matchobj = pattern.search(text)\n",
    "        if matchobj:\n",
    "            ends.append(matchobj.start())\n",
    "    return min(ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/sanghoon/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='../data/'\n",
    "mimic_folder='/ssd1/mimic3'\n",
    "save_path=data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2062914/3595589213.py:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sub_notes_have_ts=pd.read_csv(data_folder+'/sub_note.csv')\n"
     ]
    }
   ],
   "source": [
    "icustays=pd.read_csv(mimic_folder+'/ICUSTAYS.csv')\n",
    "sub_notes_have_ts=pd.read_csv(data_folder+'/sub_note.csv') \n",
    "prev_data_t =pd.read_csv(data_folder+'/preprocessed_emb_idx.csv')\n",
    "TS_data = pd.read_hdf(data_folder + '/vitals_24hourly_data_sh.h5','X')\n",
    "label_merge= pd.read_csv(data_folder + '/label_have_ts_los.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del label_merge['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prerocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_above_hours_data(data, window_size, gap_time, icustay_data):\n",
    "    icustay_data=icustay_data.rename(columns={'ICUSTAY_ID':'icustay_id','INTIME':'intime'})\n",
    "    data = data[data['max_hours']>window_size+gap_time]\n",
    "    #data.drop(columns=['los'], inplace=True)\n",
    "    data=data.astype(float)\n",
    "    data=data.merge(icustay_data[['icustay_id','intime']])\n",
    "    data= data.sort_values('intime',ascending=False)\n",
    "    last_visit_label = data[data['subject_id'].duplicated()==False]\n",
    "    print('all patient : {}'.format(len(last_visit_label['subject_id'].unique())))\n",
    "    return last_visit_label\n",
    "\n",
    "def make_note_data(note_have_ts,last_visit_label_data, window_size):\n",
    "    note_have_ts=note_have_ts.rename(columns={'SUBJECT_ID':'subject_id','HADM_ID':'hadm_id'})\n",
    "    df_adm_notes = pd.merge(note_have_ts[['ROW_ID','subject_id','hadm_id','CHARTTIME', 'CATEGORY','DESCRIPTION', 'TEXT']],\n",
    "                            last_visit_label_data[['subject_id','hadm_id','icustay_id','intime',  'mort_icu', 'mort_hosp'\n",
    "                                       ]], \n",
    "                            on = ['subject_id'],\n",
    "                            how = 'left')\n",
    "    df_adm_notes['CHARTTIME'] = pd.to_datetime(df_adm_notes['CHARTTIME'])\n",
    "    df_adm_notes['intime'] = pd.to_datetime(df_adm_notes['intime'])\n",
    "\n",
    "    df_less_n = df_adm_notes[((df_adm_notes['CHARTTIME']-df_adm_notes['intime']).dt.total_seconds()/(60*60))<window_size]\n",
    "    df_less_n = df_less_n[((df_less_n['CHARTTIME'] - df_less_n['intime']).dt.total_seconds()/(24*60*60))>0]\n",
    "    \n",
    "    sub_notes = df_less_n[df_less_n.subject_id.notnull()]\n",
    "    sub_notes = sub_notes[sub_notes.CHARTTIME.notnull()]\n",
    "    sub_notes = sub_notes[sub_notes.TEXT.notnull()]\n",
    "    sub_notes = sub_notes[['subject_id', 'hadm_id_y','CATEGORY','DESCRIPTION','CHARTTIME', 'TEXT']]\n",
    "    \n",
    "    sub_notes['preprocessed_text'] = None\n",
    "    \n",
    "    all_text = sub_notes['TEXT'].values\n",
    "    with Pool(48) as pool:\n",
    "        preprocessed_all_text = list(pool.imap(getSentences, all_text))\n",
    "        \n",
    "    sub_notes['preprocessed_text']=preprocessed_all_text\n",
    "    return sub_notes\n",
    "    \n",
    "def filter_prev_data(prev_data, last_visit_label_data):\n",
    "    prev_data=prev_data.rename(columns={'SUBJECT_ID':'subject_id'})\n",
    "    prev_data=prev_data[prev_data['subject_id'].isin(last_visit_label_data['subject_id'].unique())]\n",
    "    prev_data=prev_data.merge(last_visit_label_data[['subject_id','hadm_id','intime']],on='subject_id')\n",
    "    prev_data=prev_data[prev_data['HADM_ID']!= prev_data['hadm_id']]\n",
    "    prev_data['DISCHTIME'] = pd.to_datetime(prev_data['DISCHTIME'])\n",
    "    prev_data['intime'] = pd.to_datetime(prev_data['intime'])\n",
    "    prev_data=prev_data[prev_data['DISCHTIME']< prev_data['intime']]\n",
    "    \n",
    "    prev_data = prev_data.sort_values(['subject_id','DISCHTIME'], ascending=False)\n",
    "    prev_data['count'] = prev_data.groupby('subject_id').cumcount()+1\n",
    "    prev_data= prev_data[prev_data['count']<=10]\n",
    "    \n",
    "    print('multi visit patient : {} '.format(len(prev_data['subject_id'].unique())))\n",
    "    return prev_data\n",
    "\n",
    "def filter_monitoring_data(monitoring_data, last_visit_label_data):\n",
    "    monitoring_data=monitoring_data.reset_index()\n",
    "    monitoring_data=monitoring_data[monitoring_data['icustay_id'].isin(last_visit_label_data.icustay_id.unique())]\n",
    "    monitoring_data=monitoring_data.groupby(['subject_id','hadm_id','icustay_id','hours_in']).first()\n",
    "    \n",
    "    return monitoring_data\n",
    "def check_sub_have_modal(last_visit_label_data, modal , check_modal_data):\n",
    "    # modal = multi_visit or note\n",
    "    check_id=check_modal_data.subject_id.unique()\n",
    "    last_visit_label_data[modal] =list(map(lambda x : 1 if x in check_id else 0, last_visit_label_data['subject_id']))\n",
    "    return last_visit_label_data\n",
    "\n",
    "\n",
    "# check 24562, 17 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WINDOW=24\n",
    "GAP=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all patient : 32504\n",
      "multi visit patient : 5751 \n"
     ]
    }
   ],
   "source": [
    "last_visit_label_24_6 = make_above_hours_data(label_merge, window_size=WINDOW, gap_time=GAP,icustay_data=icustays)\n",
    "prev_data_24_6 = filter_prev_data(prev_data_t,last_visit_label_24_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "note_24_6 = make_note_data(sub_notes_have_ts,last_visit_label_24_6, WINDOW)\n",
    "last_visit_label_24_6=check_sub_have_modal(last_visit_label_24_6, 'multi_visit',prev_data_24_6)\n",
    "last_visit_label_24_6=check_sub_have_modal(last_visit_label_24_6, 'have_note',note_24_6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2062914/718504936.py:58: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  monitoring_data=monitoring_data.groupby(['subject_id','hadm_id','icustay_id','hours_in']).first()\n"
     ]
    }
   ],
   "source": [
    "ts_24_6 = filter_monitoring_data(TS_data,last_visit_label_24_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_visit_label_24_6['los_3'] =(last_visit_label_24_6['los']>3).astype(float)\n",
    "last_visit_label_24_6['los_7'] =(last_visit_label_24_6['los']>7).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17372, 7761)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(last_visit_label_24_6['los']>3).sum() , (last_visit_label_24_6['los']>=7).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanghoon/.conda/envs/py39/lib/python3.9/site-packages/tables/attributeset.py:457: NaturalNameWarning: object name is not a valid Python identifier: 'axis0_nameAggregation Function'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "/home/sanghoon/.conda/envs/py39/lib/python3.9/site-packages/tables/attributeset.py:457: NaturalNameWarning: object name is not a valid Python identifier: 'block0_items_nameAggregation Function'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n"
     ]
    }
   ],
   "source": [
    "last_visit_label_24_6.to_csv(save_path+'label_last_visit.csv',index=False)\n",
    "prev_data_24_6.to_csv(save_path+'prev_idx_data.csv', index=False)\n",
    "note_24_6.to_pickle(save_path+'preprocessed_notes.pkl')\n",
    "ts_24_6.to_hdf(save_path+'ts_24_6.h5','X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>max_hours</th>\n",
       "      <th>mort_icu</th>\n",
       "      <th>mort_hosp</th>\n",
       "      <th>los</th>\n",
       "      <th>intime</th>\n",
       "      <th>multi_visit</th>\n",
       "      <th>have_note</th>\n",
       "      <th>los_3</th>\n",
       "      <th>los_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18264</th>\n",
       "      <td>24562.0</td>\n",
       "      <td>166275.0</td>\n",
       "      <td>203462.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2506</td>\n",
       "      <td>2210-08-18 12:34:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23880</th>\n",
       "      <td>25723.0</td>\n",
       "      <td>127135.0</td>\n",
       "      <td>234115.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1249</td>\n",
       "      <td>2209-07-31 13:52:39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>2846.0</td>\n",
       "      <td>195990.0</td>\n",
       "      <td>252411.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6696</td>\n",
       "      <td>2209-02-09 22:48:52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39744</th>\n",
       "      <td>98185.0</td>\n",
       "      <td>116667.0</td>\n",
       "      <td>216102.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6906</td>\n",
       "      <td>2208-08-19 13:03:37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>7632.0</td>\n",
       "      <td>183768.0</td>\n",
       "      <td>280210.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4697</td>\n",
       "      <td>2208-05-27 02:33:27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37149</th>\n",
       "      <td>79168.0</td>\n",
       "      <td>125272.0</td>\n",
       "      <td>293960.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9252</td>\n",
       "      <td>2100-07-06 15:02:22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>1291.0</td>\n",
       "      <td>141087.0</td>\n",
       "      <td>299677.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2676</td>\n",
       "      <td>2100-07-04 10:29:48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27566</th>\n",
       "      <td>32096.0</td>\n",
       "      <td>158366.0</td>\n",
       "      <td>240498.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2924</td>\n",
       "      <td>2100-06-22 06:34:52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>12001.0</td>\n",
       "      <td>173927.0</td>\n",
       "      <td>222148.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6201</td>\n",
       "      <td>2100-06-14 04:56:39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25474</th>\n",
       "      <td>29156.0</td>\n",
       "      <td>161773.0</td>\n",
       "      <td>293407.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.8777</td>\n",
       "      <td>2100-06-09 01:39:43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32504 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject_id   hadm_id  icustay_id  max_hours  mort_icu  mort_hosp  \\\n",
       "18264     24562.0  166275.0    203462.0       54.0       0.0        0.0   \n",
       "23880     25723.0  127135.0    234115.0      170.0       0.0        0.0   \n",
       "2200       2846.0  195990.0    252411.0       40.0       0.0        0.0   \n",
       "39744     98185.0  116667.0    216102.0       40.0       0.0        0.0   \n",
       "5864       7632.0  183768.0    280210.0      131.0       0.0        0.0   \n",
       "...           ...       ...         ...        ...       ...        ...   \n",
       "37149     79168.0  125272.0    293960.0      214.0       0.0        0.0   \n",
       "1377       1291.0  141087.0    299677.0      462.0       0.0        0.0   \n",
       "27566     32096.0  158366.0    240498.0       55.0       0.0        0.0   \n",
       "8781      12001.0  173927.0    222148.0      110.0       0.0        0.0   \n",
       "25474     29156.0  161773.0    293407.0      237.0       0.0        1.0   \n",
       "\n",
       "           los               intime  multi_visit  have_note  los_3  los_7  \n",
       "18264   2.2506  2210-08-18 12:34:24            1          1    0.0    0.0  \n",
       "23880   7.1249  2209-07-31 13:52:39            1          0    1.0    1.0  \n",
       "2200    1.6696  2209-02-09 22:48:52            1          1    0.0    0.0  \n",
       "39744   1.6906  2208-08-19 13:03:37            1          1    0.0    0.0  \n",
       "5864    5.4697  2208-05-27 02:33:27            1          1    1.0    0.0  \n",
       "...        ...                  ...          ...        ...    ...    ...  \n",
       "37149   8.9252  2100-07-06 15:02:22            0          1    1.0    1.0  \n",
       "1377   19.2676  2100-07-04 10:29:48            0          1    1.0    1.0  \n",
       "27566   2.2924  2100-06-22 06:34:52            0          1    0.0    0.0  \n",
       "8781    4.6201  2100-06-14 04:56:39            0          1    1.0    0.0  \n",
       "25474   9.8777  2100-06-09 01:39:43            0          1    1.0    1.0  \n",
       "\n",
       "[32504 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_visit_label_24_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED= 0\n",
    "split_path =  save_path +'/split_'+ str(SEED) +'/'\n",
    "if os.path.isdir(split_path) == False:\n",
    "            os.mkdir(split_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_visit_label_24_6=last_visit_label_24_6.set_index('hadm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "hadm_ids =set(last_visit_label_24_6.index)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(hadm_ids)), len(hadm_ids)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "pd.to_pickle(train_subj,split_path+'train_hadm_idx.pkl' )\n",
    "pd.to_pickle(dev_subj,split_path+'dev_hadm_idx.pkl' )\n",
    "pd.to_pickle(test_subj,split_path+'test_hadm_idx.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22752, 3250, 6502)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_subj), len(dev_subj) , len(test_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>max_hours</th>\n",
       "      <th>mort_icu</th>\n",
       "      <th>mort_hosp</th>\n",
       "      <th>los</th>\n",
       "      <th>intime</th>\n",
       "      <th>multi_visit</th>\n",
       "      <th>have_note</th>\n",
       "      <th>los_3</th>\n",
       "      <th>los_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadm_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112538.0</th>\n",
       "      <td>40866.0</td>\n",
       "      <td>290354.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.8916</td>\n",
       "      <td>2104-07-01 18:06:22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180033.0</th>\n",
       "      <td>83988.0</td>\n",
       "      <td>240937.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>2143-06-19 12:17:01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194001.0</th>\n",
       "      <td>10523.0</td>\n",
       "      <td>207531.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3893</td>\n",
       "      <td>2155-03-29 08:23:03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181309.0</th>\n",
       "      <td>8934.0</td>\n",
       "      <td>295861.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4743</td>\n",
       "      <td>2108-12-23 11:45:29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198791.0</th>\n",
       "      <td>6241.0</td>\n",
       "      <td>213875.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6259</td>\n",
       "      <td>2177-09-16 22:45:08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167424.0</th>\n",
       "      <td>9666.0</td>\n",
       "      <td>248058.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4439</td>\n",
       "      <td>2105-01-21 12:21:29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191586.0</th>\n",
       "      <td>24409.0</td>\n",
       "      <td>218258.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6372</td>\n",
       "      <td>2157-02-02 21:25:08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130747.0</th>\n",
       "      <td>63074.0</td>\n",
       "      <td>289210.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9085</td>\n",
       "      <td>2189-05-29 20:22:26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182269.0</th>\n",
       "      <td>15246.0</td>\n",
       "      <td>200933.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9805</td>\n",
       "      <td>2157-11-13 19:03:50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186549.0</th>\n",
       "      <td>87782.0</td>\n",
       "      <td>247945.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0579</td>\n",
       "      <td>2184-05-03 10:21:14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22752 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject_id  icustay_id  max_hours  mort_icu  mort_hosp      los  \\\n",
       "hadm_id                                                                     \n",
       "112538.0     40866.0    290354.0      333.0       0.0        0.0  13.8916   \n",
       "180033.0     83988.0    240937.0       52.0       0.0        1.0   2.1800   \n",
       "194001.0     10523.0    207531.0       57.0       0.0        0.0   2.3893   \n",
       "181309.0      8934.0    295861.0       35.0       0.0        1.0   1.4743   \n",
       "198791.0      6241.0    213875.0      327.0       0.0        0.0  13.6259   \n",
       "...              ...         ...        ...       ...        ...      ...   \n",
       "167424.0      9666.0    248058.0       82.0       0.0        0.0   3.4439   \n",
       "191586.0     24409.0    218258.0       39.0       0.0        0.0   1.6372   \n",
       "130747.0     63074.0    289210.0      117.0       0.0        0.0   4.9085   \n",
       "182269.0     15246.0    200933.0      119.0       0.0        0.0   4.9805   \n",
       "186549.0     87782.0    247945.0       97.0       0.0        0.0   4.0579   \n",
       "\n",
       "                       intime  multi_visit  have_note  los_3  los_7  \n",
       "hadm_id                                                              \n",
       "112538.0  2104-07-01 18:06:22            0          1    1.0    1.0  \n",
       "180033.0  2143-06-19 12:17:01            0          1    0.0    0.0  \n",
       "194001.0  2155-03-29 08:23:03            0          1    0.0    0.0  \n",
       "181309.0  2108-12-23 11:45:29            0          1    0.0    0.0  \n",
       "198791.0  2177-09-16 22:45:08            0          1    1.0    1.0  \n",
       "...                       ...          ...        ...    ...    ...  \n",
       "167424.0  2105-01-21 12:21:29            0          1    1.0    0.0  \n",
       "191586.0  2157-02-02 21:25:08            0          1    0.0    0.0  \n",
       "130747.0  2189-05-29 20:22:26            0          1    1.0    0.0  \n",
       "182269.0  2157-11-13 19:03:50            0          1    1.0    0.0  \n",
       "186549.0  2184-05-03 10:21:14            0          1    1.0    0.0  \n",
       "\n",
       "[22752 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_visit_label_24_6.loc[train_subj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess for ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature=ts_24_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "\n",
    "def simple_imputer(df):\n",
    "    idx = pd.IndexSlice\n",
    "    df = df.copy()\n",
    "    if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "    \n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "    \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "    \n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "    \n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "    \n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sub_index=list(set(ts_feature.index.get_level_values('subject_id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 32504/32504 [3:16:12<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "time_list = [i for i in range(WINDOW)]\n",
    "for sub_id in tqdm.tqdm(all_sub_index):\n",
    "    sub_df=ts_feature.loc[sub_id]\n",
    "    hadm_id, icu_id, _ = sub_df.index[0]\n",
    "    tmp_hours=sub_df.index.get_level_values('hours_in')\n",
    "    for time in time_list:\n",
    "        if time not in tmp_hours:\n",
    "            try:\n",
    "                ts_feature.loc[sub_id,hadm_id,icu_id,time] = ts_feature.loc[sub_id,hadm_id,icu_id,time-1]\n",
    "            except:\n",
    "                nearest_index = tmp_hours[np.argmin(np.abs(tmp_hours - time))]\n",
    "                ts_feature.loc[sub_id,hadm_id,icu_id,time] = ts_feature.loc[sub_id,hadm_id,icu_id,nearest_index]\n",
    "    ts_feature.index = ts_feature.index.set_names(['subject_id','hadm_id','icustay_id','hours_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32504, 24, 312)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_feature=ts_feature.sort_index()\n",
    "ts_feature=ts_feature.loc[:,:,:,:WINDOW-1]\n",
    "ts_feature.values.reshape(-1,WINDOW,312).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2062914/3964367696.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "ts_feature_filed=simple_imputer(ts_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(ts_feature,save_path+'ts_feature.pkl')\n",
    "pd.to_pickle(ts_feature_filed,save_path+'ts_feature_simple_impute.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts = ts_feature_filed[ts_feature_filed.index.get_level_values('hadm_id').isin(train_subj)]\n",
    "dev_ts = ts_feature_filed[ts_feature_filed.index.get_level_values('hadm_id').isin(dev_subj)]\n",
    "test_ts = ts_feature_filed[ts_feature_filed.index.get_level_values('hadm_id').isin(test_subj)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "lvl2_means, lvl2_stds = train_ts.loc[:, idx[:,'mean']].mean(axis=0), train_ts.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "train_ts.loc[:, idx[:,'mean']] = (train_ts.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "dev_ts.loc[:, idx[:,'mean']] = (dev_ts.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "test_ts.loc[:, idx[:,'mean']] = (test_ts.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts=train_ts.loc[:, pd.IndexSlice[:, 'mean']]\n",
    "dev_ts=dev_ts.loc[:, pd.IndexSlice[:, 'mean']]\n",
    "test_ts=test_ts.loc[:, pd.IndexSlice[:, 'mean']]\n",
    "\n",
    "train_ts.to_pickle(split_path+'train_ts_simple_impute.pkl')\n",
    "test_ts.to_pickle(split_path+'test_ts_simple_impute.pkl')\n",
    "dev_ts.to_pickle(split_path+'dev_ts_simple_impute.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESAM_py39",
   "language": "python",
   "name": "desam_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
